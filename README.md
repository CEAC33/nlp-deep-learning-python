# nlp-deep-learning-python

## Intro, Outline and Review

1 - Word Embeddings: Word2Vec and GloVe

Word Embeddings allow you to map words into a vector space.
Once you can represent something as a vector you can perform arithmetic on it.
This is where the famous King minus man equals Queen minus woman comes from.

2 - Deep Neural Networks for NLP (Recurrent Neural Networks) 

Recurrent Neural Networks are special kinds of neural networks that allow us to model sequences.
And the reason why that's useful of course is because a sentence is nothing but a sequence of words.

3 - Recursive Neural Networks, How do we make sense of sentences?

A sentence is made up of a group of phrases and each of those phrases could be made up of smaller phrases.
We don't make sense of sentences by thinking of each word from start to ends but rather by the relationships between these phrases.

In other words a sentence is more like a tree and therefore one might infer a neural network shaped like a tree or a recursive neural network might be the best type of neural network for tasks such as text classification.


